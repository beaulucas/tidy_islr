\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={A Tidy Introduction To Statistical Learning},
            pdfauthor={Beau Lucas},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{A Tidy Introduction To Statistical Learning}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Beau Lucas}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2019-10-25}

\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

This book will serve as a source of notes and exercise solutions for \emph{An Introduction to Statistical Learning}. My approach will be centered around the \texttt{tidyverse}. This is not a replacement for the book, which should be read front to back by all machine learning enthusiasts.

Chapter names will line up, and certain subheadings will also match. Sometimes my notes will contain text lifted straight from the book without modification. This is not an attempt to plagiarize or claim their writing as my own. My goal is for this bookdown project to be a quick stop for machine learning enthusiasts to reference high-level ideas from ISLR in a modern media format.

\hypertarget{intro}{%
\chapter{Introduction}\label{intro}}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{an-overview-of-statistical-learning}{%
\section{An Overview of Statistical Learning}\label{an-overview-of-statistical-learning}}

Statistical learning is focused on supervised and unsupervised modeling and prediction.

\hypertarget{data-sets-used-in-labs-and-exercises}{%
\section{Data Sets Used in Labs and Exercises}\label{data-sets-used-in-labs-and-exercises}}

All data sets used in this book can be found in \texttt{ISLR} and \texttt{MASS} packages, with some also being found in the base \texttt{R} distribution.

We will utilize the \texttt{tidyverse} ecosystem to tackle the exercises and labs, as the \texttt{R} code found in the original textbook is outdated.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ISLR)}
\KeywordTok{library}\NormalTok{(MASS)}
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(knitr)}
\KeywordTok{library}\NormalTok{(kableExtra)}
\KeywordTok{library}\NormalTok{(modelr)}
\KeywordTok{library}\NormalTok{(broom)}
\end{Highlighting}
\end{Shaded}

\hypertarget{book-website}{%
\section{Book Website}\label{book-website}}

The website and free PDF for the book can be found here:

\href{http://www-bcf.usc.edu/~gareth/ISL/}{www.statlearning.com}

And here are the YouTube lectures an R labs:

\href{https://www.youtube.com/channel/UC4OWDcPB1peiBXDfCSZ3h-w}{Youtube - Statistical Learning}

\hypertarget{statistical-learning}{%
\chapter{Statistical Learning}\label{statistical-learning}}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{what-is-statistical-learning}{%
\section{What is Statistical Learning?}\label{what-is-statistical-learning}}

Methods to estimate functions that connect inputs to outputs.

If there exists a quantitative response variable \(Y\) and \(p\) different predictors (\(X_1\), \(X_2\), \ldots{}, \(X_p\)), we can write this relationship as:

\(Y = f(X) + ε\)

\hypertarget{why-estimate-f}{%
\subsection{\texorpdfstring{Why Estimate \emph{\(f\)}?}{Why Estimate f?}}\label{why-estimate-f}}

\hypertarget{prediction}{%
\subsubsection{Prediction}\label{prediction}}

We can predict Y using:

\(\hat{Y} = \hat{f}(X)\)

Accuracy of \(Y\) is dependant on:

\begin{itemize}
\tightlist
\item
  \emph{reducible error}

  \begin{itemize}
  \tightlist
  \item
    \(\hat{f}\) will never be perfect estimate of \(f\), and model can always be potentially improved
  \item
    Even if \(\hat{f} = f\), prediction would still have some error
  \end{itemize}
\item
  \emph{irreducible error}

  \begin{itemize}
  \tightlist
  \item
    Because \(Y\) is also a function of random \(ε\), there will always be variability
  \item
    We cannot reduce the error introduced by \(ε\)
  \end{itemize}
\end{itemize}

\hypertarget{inference}{%
\subsubsection{Inference}\label{inference}}

How does \(Y\) respond to changes in \(X_1, X_2, ..., X_p\)?

\hypertarget{how-do-we-estimate-f}{%
\subsection{\texorpdfstring{How do we estimate \emph{\(f\)}?}{How do we estimate f?}}\label{how-do-we-estimate-f}}

\begin{itemize}
\tightlist
\item
  Use \emph{training data} to train method
\item
  \(x_ij\) is value of \(j\)th predictor for observation \(i\), \(y_i\) is value of response variable

  \begin{itemize}
  \tightlist
  \item
    \(i = 1, 2, ..., n\), \(j = 1, 2, ..., p\)
  \end{itemize}
\item
  Using training data, apply statistical learning method estimate unknown function \(f\)
\item
  Most statistical learning methods can be characterized as either \emph{parametric} or \emph{non-parametric}
\end{itemize}

\hypertarget{parametric-methods}{%
\subsubsection{Parametric Methods}\label{parametric-methods}}

Two-step model-based approach:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Make an assumption about functional form of \(f\), such as ``\(f\) is linear in \(X\)''
\item
  Perform procedure that uses training data to train the model
  * In case of linear model, this procedure estimates parameters \(β_0, β_1, ..., β_p\)
  * Most common approach to fit linear model is \emph{(ordinary) least squares}
\end{enumerate}

This is \emph{parametric}, as it reduces the problem of estimating \(f\) down to one of estimating a set of parameters. Problems that can arise:

\begin{itemize}
\tightlist
\item
  Model will not match the true unknown form of \(f\)
\item
  If model is made more \emph{flexible}, which generally requires estimating a greater number of parameters, \emph{overfitting} can occur
\end{itemize}

\hypertarget{non-parametric-methods}{%
\subsubsection{Non-parametric Methods}\label{non-parametric-methods}}

Non-parametric methods do not make assumptions about the form of \(f\). An advantage of this is that they have the potential to fit a wider range of possible shapes for \(f\). A disadvantage is that, because there are no assumptions about the form of \(f\), the problem of estimating \(f\) is not reduced to a set number of parameters. This means more observations are needed compared to a parametric approach to estimate \(f\) accurately.

\hypertarget{the-trade-off-between-prediction-accuracy-and-model-interpretability}{%
\subsection{The Trade-Off Between Prediction Accuracy and Model Interpretability}\label{the-trade-off-between-prediction-accuracy-and-model-interpretability}}

Restrictive models are much more intepretable than flexible ones. Flexible approaches can be so complicated that it is hard to understand how predictors affect the response.

If inference is the goal, simple and inflexible methods are easier to interpret. For prediction, accuracy is the biggest concern. However, flexible models are more prone to overfitting.

\hypertarget{supervised-versus-unsupervised-learning}{%
\subsection{Supervised Versus Unsupervised Learning}\label{supervised-versus-unsupervised-learning}}

Most machine learning methods can be split into \emph{supervised} or \emph{unsupervised} categories. Most of this textbook involves supervised learning methods, in which a model that captures the relationship between predictors and response measurements is fitted. The goal is to accurately predict the response variables for future observations, or to understand the relationship between the predictors and response.

Unsupervised learning takes place when we have a set of observations and a vector of measurements \(x_i\), but no response \(y_i\). We can examine the relationship between the variables or between the observations. A popular method of unsupervised learning is \href{https://en.wikipedia.org/wiki/Cluster_analysis}{cluster analysis}, in which observations are grouped into distinct groups based on their vector of measurements \(x_i\). An example of this would be a company segmenting survey respondents based on demographic data, in which the goal is to ascertain some idea about potential spending habits without possessing this data.

Clustering has some drawbacks. It works best when the groups are significantly distinct from each other. In reality, it is rare for data to exhibit this characteristic. There is often overlap between observations in different groups, and clustering will inevitably place a number of observations in the wrong groups. Further more, visualization of clusters breaks down as the dimensionality of data increases. Most data contains at least several, if not dozens, of variables.

It is not always clear-cut whether a problem should be handled with supervised or unsupervised learning. There are some scenarios where only a subset of the observations have response measurements. This is a \emph{semi-supervised learning} problem, in which a statistical learning method that can utilize all observations is needed.

\hypertarget{regression-versus-classification-problems}{%
\subsection{Regression Versus Classification Problems}\label{regression-versus-classification-problems}}

Variables can be categorized as either \emph{quantitative} or \emph{qualitative}. Both qualitative and quantatitive predictors can be used to predict both types of response variables. The more important part of choosing an appropriate statistical learning method is the type of the response variable.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{assessing-model-accuracy}{%
\section{Assessing Model Accuracy}\label{assessing-model-accuracy}}

Every data set is different and there is no one statistical learning method that works best for all data sets. It is important for any given data set to find the statistical learning method that produces the best results. This section presents some concepts that are part of that decision-making process.

\hypertarget{measuring-the-quality-of-fit}{%
\subsection{Measuring the Quality of Fit}\label{measuring-the-quality-of-fit}}

We need to be able to quantify how well a model's predictions match the observed data. How close are the model's predicted response values to the true response values?

In regression, \href{https://en.wikipedia.org/wiki/Mean_squared_error}{\emph{mean squared error (MSE)}} is the most commonly-used measure. A small MSE indicates the predicted responses are very close to the true ones. MSE used on training data is more accurately referred to as the \emph{training MSE}.

We are most concerned with the accuracy of the predictions when we apply our methods to \textbf{previously unseen data}. If you are trying to predict the value of a stock, your concern is how it performs in the future, not on known data from the past. Thus, the goal is then minimizing the \emph{test MSE}, which measures the accuracy of a model on \textbf{observations that were not used to train the model}. Imagine a set of observations \((x_0, y_0)\) that were not used to train the statistical learning method.

\(Ave(y_0 - \hat{f}(x_0))2\)

The goal is to select the model that minimizes the test MSE shown above. How can we do this?

Sometimes, there is an available test data set full of observations that were not used in training the model. The test MSE can be evaluated on these observations, and the learning method which produces the smallest TSE will be chosen. If no test observations are available, picking the method that minimizes the training MSE might seem to be a good idea. However, there is no guarantee that a model with the lowest training MSE also has the lowest test MSE. Models often work in minimizing the training MSE, and can end up with large test MSE.

There is a tradeoff in model flexibility, training MSE, and test MSE. A model that is too flexible can closely match the training data, but perform poorly on the test data. There is a sweet spot to find between model flexibility, training MSE, and test MSE that varies for each unique data set.

\emph{Degrees of freedom} is a quantity that summarizes the flexibility of a curve, discused more fully in Chapter 7. The more inflexible a model is, the fewer degrees of freedom.

As model flexibility increases, training MSE will inevitably decrease, but test MSE may plateau or even rise. A model with a small training MSE and large test MSE is \emph{overfitting the data}, picking up patterns on the training data that don't exist in the test data. Since we expect the training MSE to almost always be lower than the test MSE, overfitting is a specific case when there exists a less flexible model with a smaller test MSE.

\hypertarget{the-bias-variance-trade-off}{%
\subsection{The Bias-Variance Trade-Off}\label{the-bias-variance-trade-off}}

The expected test MSE can be broken down into the sum of three quantities:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the \emph{variance} of \(\hat{f}(x_0)\)
\item
  the squared \emph{bias} of \(\hat{f}(x_0)\)
\item
  the variance of the error terms ε
\end{enumerate}

\(E(y_0 - \hat{f}(x_0)^2 = Var(\hat{f}(x_0)) + [Bias(\hat{f}(x_0))]^2+Var(ε)\)

The formula above defines the \emph{expected test MSE}, which can be thought of the average test MSE that would be obtained if we repeatedly estimated \(f\) and tested each at \(x_0\). To minimize expected test MSE, we need to choose a statistical learning method that achieves both low variance and low bias. Since variance and squared bias are nonnegative, the expected test MSE can never be lower than \(Var(ε)\), the irreducible error.

\emph{Variance} refers to how much \(\hat{f}\) would change if repeatedly estimated with different training data sets. Methods with high variance can produce large changes in \(\hat{f}\) through small changes in the training data. Generally, the more flexible a model it is, the higher the variance. Following the observations so closely can cause changes in just a single observation of the training data to result in significant changes to \(\hat{f}\). More inflexible models, such as linear regression, are less susceptible to the effects of changing a single observation.

\emph{Bias} is the error introduced from approximating a complicated problem by a much simpler model. Fitting a linear regression to data that is not linear will always lead to high bias, no matter how many observations are in the training set. More flexible models tend to result in less bias.

More flexible methods lead to higher variance and lower bias. The rate of change between the quantities determines at which point the test MSE is minimized. Bias tends to decrease at a faster rate in the beginning, causing the test MSE to decline. However, when flexibility reaches a certain point, variance will begin to increase faster than bias is decreasing, causing test MSE to rise.

This relationship between bias, variance, and test MSE is known as the \emph{bias-variance tradeoff}. Here is a good article on it: \href{http://scott.fortmann-roe.com/docs/BiasVariance.html}{Understanding the Bias-Variance Tradeoff}

In real-life scenarios where \(f\) is unknown, we cannot explicitly compute the test MSE, bias, or variance. However, there are methods to estimate this, such as \emph{cross-validation}, which will be discussed in Chapter 5.

\hypertarget{the-classification-setting}{%
\subsection{The Classification Setting}\label{the-classification-setting}}

For classification problems where \(y_i,...,y_n\) are qualitative, we can quantify the accuracy of our estimate by using the \emph{training error rate}, the proportion of mistakes that are made when applying our model \(\hat{f}\) to the training observations.

\(1/n\sum_{i=1}^nI(y_i \neq \hat{y_i})\)

\emph{training error rate}

Breaking the formula above down.

\begin{itemize}
\tightlist
\item
  \(\hat{y}_i\) is the predicted class label for the \(i\)th observation using \(\hat{f}\)
\item
  \(I(y_i \neq \hat{y_i})\) is an \emph{indicator variable} that equals 1 if \(y_i \neq \hat{y_i}\), and 0 if \(y_i = \hat{y_i}\)
\item
  If \(I(y_i \neq \hat{y_i})\) = 0, then the \(i\)th observation was classified correctly
\end{itemize}

Similar to our regression problems, we are more interested in the model's performance on test observations not used in training. The formula below gives us the \emph{test error rate} for a set of observations of the form \((x_0, y_0)\).

\(Ave(I(y_0 \neq \hat{y_0}))\)

\emph{test error rate}

A good classifier will minimize the above.

\hypertarget{the-bayes-classifier}{%
\subsubsection{The Bayes Classifier}\label{the-bayes-classifier}}

The \emph{test error rate} is minimized by the classifier that assigns each observation to the most likely class, given its predictor values. Our decision is then based on finding the value at which the formula below is largest.

\(Pr(Y = j|X = x_0)\)

If the response values are binomial (let's call them A and B) the classifier simplifies to:

\(Pr(Y = A|X = x_0) > 0.5\:then\:A,\:else\:B\)

The \emph{Bayes decision boundary} is the point where the probabilities are equal for both groups. Points on either side of this line are assigned to the group predicted by the classifier. The \emph{Bayes error rate} averaged over all possible values of \(X\) is below.

\(1-E(max_jPr(Y = j|X))\)

\emph{Bayes error rate}

The \emph{Bayes error rate} is often greater than zero, as observations between classes overlap in real-world data.

\hypertarget{k-nearest-neighbors}{%
\subsubsection{K-Nearest Neighbors}\label{k-nearest-neighbors}}

Since the true conditional distribution of \(Y\) given \(X\) cannot be known in real data, the Bayes classifier is used as a ``gold standard'' to compare other models to. Many methods attempt to estimate this conditional distribution, and then classify an observation based on the estimated probability. A common method is \emph{K-nearest neighbors (KNN)}. Given a positive integer \(K\) and a test observation \(x_0\), KNN then does the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  identifies the \(K\) points in the training data that are closest to \(x_0\), represented by \(N_0\)
\item
  estimates conditional probability for class \(j\) as the fraction of the points in \(N_0\) whose response values equal \(j\):
\end{enumerate}

\(Pr(Y = j| X = x_0) = 1/K\sum_{i\in N_0}I(y_i = j)\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  applies Bayes rule and classifies test observation \(x_0\) to class with largest probability
\end{enumerate}

KNN can be surprisingly robust to the optimal Bayes classifier. The choice in \(K\) makes a huge difference. For example, a \(K\) = 1 is highly flexible, classifying observations based off of the closest nearby training observation. \(K\) = 100 would do the opposite, basing its classification off a large pool of training observations compared to the \(K\) = 1 version. The higher \(K\) value produces a more linear model. The trade-off between flexibility, training error rate, and test error rate applies to both classification and regression problems.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{lab-introduction-to-r}{%
\section{Lab: Introduction to R}\label{lab-introduction-to-r}}

Finally we get to some \texttt{R} code. This chapter of ISLR introduces basic \texttt{R} syntax, and most of it is unchanged in my version. This should all be familiar to anyone who has used R before.

We are going to be working with \texttt{tibbles} as our primary data structure throughout this book. Please read here: \href{http://r4ds.had.co.nz/tibbles.html}{tibbles}

\hypertarget{basic-commands}{%
\subsubsection{Basic Commands}\label{basic-commands}}

Skipping this.

\hypertarget{graphics-plotting}{%
\subsubsection{Graphics (Plotting)}\label{graphics-plotting}}

Here we begin to explore the ``tidy'' approach to R. We will abstain from base R plotting and use \texttt{ggplot2}, which is a more powerful tool. Let's plot a scatterplot with some basic labels.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tbl_rnorm <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{x1 =} \KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{),}
  \DataTypeTok{y1 =} \KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{)}

\KeywordTok{ggplot}\NormalTok{(tbl_rnorm, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x1, }\DataTypeTok{y =}\NormalTok{ y1)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"plot of x1 vs. y1"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"this is the x-axis"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"this is the y-axis"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-1-1} \end{center}

\hypertarget{indexing-data}{%
\subsubsection{Indexing data}\label{indexing-data}}

We will skip this.

\hypertarget{loading-data}{%
\subsubsection{Loading data}\label{loading-data}}

\emph{ISLR} mentions insuring proper working directory before loading data. Dealing with working directories in R is a bad idea. Fortunately, it's easily avoidable through the use of RStudio \emph{projects}, which keep all files used in analysis together and make your work more robust and reproducible. See the \href{http://r4ds.had.co.nz/workflow-projects.html}{RStudio Projects} chapter in \emph{r4ds} for more information.

We will opt for the \texttt{readr} (part of the \texttt{tidyverse}) package instead of base R. Take a look at this subsection of \emph{r4ds} for reasons why:
\href{http://r4ds.had.co.nz/data-import.html}{\emph{11.2.1 Compared to base R}}

Below is a reproducible example in which we create a tibble, save it as a .txt file, and then read it in with \texttt{write\_tsv()}. The set of \texttt{read\_*} functions in \texttt{readr} will be the standrad way to read local files into R. If you are using RStudio projects, there is no need to worry about working directories.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# generate dummy data to read in}
\NormalTok{generic_company_tibble <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{x =} \KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DataTypeTok{mean =} \DecValTok{25}\NormalTok{),}
  \DataTypeTok{y =} \KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DataTypeTok{mean =} \DecValTok{50}\NormalTok{),}
  \DataTypeTok{z =} \KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"apple"}\NormalTok{, }\StringTok{"uber"}\NormalTok{, }\StringTok{"facebook"}\NormalTok{, }\StringTok{"twitter"}\NormalTok{, }\StringTok{"tesla"}\NormalTok{, }\StringTok{"google"}\NormalTok{, }\StringTok{"microsoft"}\NormalTok{), }\DecValTok{1}\NormalTok{)}
\NormalTok{)}

\NormalTok{tmp <-}\StringTok{ }\KeywordTok{tempfile}\NormalTok{()}
\KeywordTok{write_tsv}\NormalTok{(generic_company_tibble, tmp)}
\NormalTok{company_data <-}\StringTok{ }\KeywordTok{read_tsv}\NormalTok{(tmp)}
\end{Highlighting}
\end{Shaded}

\texttt{readr} provides a nice summary of the imported tibble. Calling the tibble by name will also give a breakdown of column names, data types, and number of observations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{company_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 100 x 3
##       x     y z       
##   <dbl> <dbl> <chr>   
## 1  26.7  50.7 facebook
## 2  23.9  49.1 facebook
## 3  23.8  50.4 facebook
## 4  25.0  51.4 facebook
## 5  25.8  51.0 facebook
## 6  26.5  49.6 facebook
## # ... with 94 more rows
\end{verbatim}

\hypertarget{additional-graphical-and-numerical-summaries}{%
\subsubsection{Additional Graphical and Numerical Summaries}\label{additional-graphical-and-numerical-summaries}}

ISLR mentions the \texttt{attach()} function, which allows R to reference column names of dataframes without specifying the dataframe. \texttt{attach} can lead to confusion and errors when working on a project with multiple sources of data. This is a bad practice, and should always be avoided.

The book then goes into some explanation of \texttt{plot()}, which we will not be using.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{exercises}{%
\section{Exercises}\label{exercises}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method.

  \begin{enumerate}
  \def\labelenumii{(\alph{enumii})}
  \tightlist
  \item
    The sample size n is extremely large, and the number of predictors p is small

    \begin{itemize}
    \tightlist
    \item
      \textbf{(better)} given large sample size, a flexible model would be able to capture a trend without being influenced too heavily by a small number of observations.
    \end{itemize}
  \item
    The number of predictors p is extremely large, and the number of observations n is small.

    \begin{itemize}
    \tightlist
    \item
      \textbf{(worse)} given the small sample size, an inflexible model would do better at not overfitting to a small number of observations (capturing patterns in the training data that dont really exist)
    \end{itemize}
  \item
    The relationship between the predictors and response is highly non-linear.

    \begin{itemize}
    \tightlist
    \item
      \textbf{(better)} highly flexible methods are highly non-linear and can produce better fits on non-linear data compared to inflexible methods such as linear regression
    \end{itemize}
  \item
    The variance of the error terms, i.e.~σ2 = Var(ε), is extremely high.

    \begin{itemize}
    \tightlist
    \item
      \textbf{(worse)} given the high variance in the data, an inflexible method would overfit to the noise
    \end{itemize}
  \end{enumerate}
\item
  Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.

  \begin{itemize}
  \tightlist
  \item
    \textbf{(regression; inference)} This is a regression problem with both qualitative and quantitative predictors. Inference is the main goal, as the company probably wants a model that is human-readable in order to understand what determines a CEO's salary.

    \begin{itemize}
    \tightlist
    \item
      \texttt{n\ =\ 500,\ p\ =\ 3}
    \end{itemize}
  \end{itemize}
\item
  We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.

  \begin{itemize}
  \tightlist
  \item
    \textbf{(classification; prediction)} The goal is to classify whether a product will be a success or failure. Prediction is the goal, as they want to accurately determine if their product will succeed or fail.

    \begin{itemize}
    \tightlist
    \item
      \texttt{n\ =\ 20,\ p\ =\ 4}
    \end{itemize}
  \end{itemize}
\item
  We are interested in predicting the \% change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the \% change in the USD/Euro, the \% change in the US market, the \% change in the British market, and the \% change in the German market.

  \begin{itemize}
  \tightlist
  \item
    \textbf{(regression; prediction)} The goal is to predict the \% change of the exchange rate.
  \end{itemize}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  We now revisit the bias-variance decomposition
\end{enumerate}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bias_variance <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{flexibility =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{),}
  \DataTypeTok{bias =} \KeywordTok{c}\NormalTok{(}\DecValTok{300}\NormalTok{,}\DecValTok{200}\NormalTok{,}\DecValTok{150}\NormalTok{,}\DecValTok{100}\NormalTok{,}\DecValTok{50}\NormalTok{),}
  \DataTypeTok{variance =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{25}\NormalTok{,}\DecValTok{125}\NormalTok{,}\DecValTok{250}\NormalTok{,}\DecValTok{500}\NormalTok{),}
  \DataTypeTok{train_error =} \KeywordTok{c}\NormalTok{(}\DecValTok{350}\NormalTok{,}\DecValTok{250}\NormalTok{,}\DecValTok{200}\NormalTok{, }\DecValTok{125}\NormalTok{, }\DecValTok{50}\NormalTok{),}
  \DataTypeTok{irreducible_error =} \DecValTok{100}\NormalTok{,}
  \DataTypeTok{test_error =}\NormalTok{ variance }\OperatorTok{+}\StringTok{ }\NormalTok{bias }\OperatorTok{+}\StringTok{ }\NormalTok{irreducible_error) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\StringTok{`}\DataTypeTok{bias}\StringTok{`}\NormalTok{, }\StringTok{`}\DataTypeTok{variance}\StringTok{`}\NormalTok{, }\StringTok{`}\DataTypeTok{train_error}\StringTok{`}\NormalTok{, }\StringTok{`}\DataTypeTok{irreducible_error}\StringTok{`}\NormalTok{, }\StringTok{`}\DataTypeTok{test_error}\StringTok{`}\NormalTok{,}
         \DataTypeTok{key =} \StringTok{"measurement"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"value"}\NormalTok{)}

\KeywordTok{ggplot}\NormalTok{(bias_variance, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ flexibility, }\DataTypeTok{y =}\NormalTok{ value, }\DataTypeTok{colour =}\NormalTok{ measurement)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{, }\DataTypeTok{formula =}\NormalTok{ y }\OperatorTok{~}\StringTok{ }\KeywordTok{poly}\NormalTok{(x,}\DecValTok{3}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-4-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  You will now think of some real-life applications for statistical learning.

  \begin{enumerate}
  \def\labelenumii{(\alph{enumii})}
  \tightlist
  \item
    Describe three real-life applications in which classification might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.

    \begin{enumerate}
    \def\labelenumiii{\arabic{enumiii}.}
    \tightlist
    \item
      predicting diabetes.

      \begin{itemize}
      \tightlist
      \item
        response: future diabetes
      \item
        predictors: health and body measurements of patient
      \item
        goal: prediction, model complexity and human understanding is not important
      \end{itemize}
    \item
      demographics that determine future education level

      \begin{itemize}
      \tightlist
      \item
        response: education level
      \item
        predictors: demographic data
      \item
        goal: inference, prediction is important here too but researchers would probably want to understand and share which factors determine the response in order to raise awareness
      \end{itemize}
    \item
      faulty parts in manufacturing

      \begin{itemize}
      \tightlist
      \item
        response: whether or not part is faulty
      \item
        predictors: various tests on part
      \item
        goal: prediction, it is most important to have an accurate model, especially if faulty parts can lead to deaths
      \end{itemize}
    \end{enumerate}
  \item
    Describe three real-life applications in which regression might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.

    \begin{enumerate}
    \def\labelenumiii{\arabic{enumiii}.}
    \tightlist
    \item
      number of riders on public transit over time

      \begin{itemize}
      \tightlist
      \item
        response: how many riders are expected to use public transit
      \item
        predictors: current transit usage data, local population data, etc.
      \item
        goal: prediction, it is important to prepare for growth in transit usage so governments have enough time to make necessary changes
      \end{itemize}
    \item
      demand for product

      \begin{itemize}
      \tightlist
      \item
        response: how many units to expect to be sold
      \item
        predictors: current demand data, revenue growth, business expansion, changing in market trends, economy health
      \item
        goal: prediction, figure out in X amount of time demand for product in order to upsize/downsize to appropriate level
      \end{itemize}
    \item
      determine future salary

      \begin{itemize}
      \tightlist
      \item
        response: future expeceted salary
      \item
        predictors: employment history, education, geolocation, etc.
      \item
        goal: inference, researchers might want to know the most important factors that lead to higher salaries rather than a model that is too complex to understand
      \end{itemize}
    \end{enumerate}
  \end{enumerate}
\item
  What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Very flexible approach allows you to fit a more flexible function to the data. The advantage is that you have the potential to accurately predict data even as it moves away from linearity. The disadvantage are potential overfitting to the training data, increasing variance (individual observations affect the model to higher degree than non-flexible counterpart), and higher computational costs (as well as less human-readable explanations)
\item
  When a more flexible approach is preferred: data that is non-linear, large sample size, prediction more important than inference
\item
  When a less flexible approach is preferred: data that is more linear, smaller sample size, inference more important than prediction
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a nonparametric approach)? What are its disadvantages?
\end{enumerate}

\begin{itemize}
\tightlist
\item
  A parametric approach assumes a form of \(f\) and has to estimate an often known number of parameters (for example, linear regression simply requires estimating \(p+1\) coefficients)
\item
  A non-parametric approach makes no assumptions about the true form of \(f\). They simply want to get as close as possible to \(f\). This allows them to take on a larger variety of shapes, and accomodate a larger variety of patterns.
\item
  Advantages of a parametric approach are that they take less observations to generate (the problem is reduced to applying a known form to \(f\), such as linear regression), are less inclined to overfit, and generally less computationally intensive.
\item
  Disadvantages of a parametric approach making assumptions about the form of \(f\), which may not match the real form and could lead to a model that doesn't fit the data well
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  The table below provides a training data set containing six observa- tions, three predictors, and one qualitative response variable.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training_set <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\OperatorTok{-}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),}
  \DataTypeTok{x3 =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
  \DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{,}\StringTok{"red"}\NormalTok{,}\StringTok{"red"}\NormalTok{,}\StringTok{"green"}\NormalTok{,}\StringTok{"green"}\NormalTok{,}\StringTok{"red"}\NormalTok{))}

\KeywordTok{kable}\NormalTok{(training_set)}
\end{Highlighting}
\end{Shaded}

x1

x2

x3

y

0

3

0

red

2

0

0

red

0

1

3

red

0

1

2

green

-1

0

1

green

1

1

1

red

Suppose we wish to use this data set to make a prediction for \(Y\) when \(X1 = X2 = X3 = 0\) using K-nearest neighbors.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Compute the Euclidean distance between each observation and the test point, \(X1 = X2 = X3 = 0\).
\end{enumerate}

The Euclidean Distance for three dimensions can be written as:

\(d = \sqrt {\left( {x_1 - x_2 } \right)^2 + \left( {y_1 - y_2 } \right)^2 + \left( {z_1 - z_2 } \right)^2 }\)

Let's write a function that can handle this in R, then use the \texttt{rowwise()} feature of dplyr to apply it across the rows of our tibble.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{euc_dist <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x1, x2) }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{sum}\NormalTok{((x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{))}
\NormalTok{training_set <-}\StringTok{ }\NormalTok{training_set }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rowwise}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{distance =} \KeywordTok{euc_dist}\NormalTok{(}\KeywordTok{c}\NormalTok{(x1,x2,x3), }\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}

\KeywordTok{kable}\NormalTok{(training_set)}
\end{Highlighting}
\end{Shaded}

x1

x2

x3

y

distance

0

3

0

red

3.000000

2

0

0

red

2.000000

0

1

3

red

3.162278

0

1

2

green

2.236068

-1

0

1

green

1.414214

1

1

1

red

1.732051

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  What is our prediction with K = 1? Why?
\end{enumerate}

Let's find the \texttt{y} value of the single closest (\texttt{k\ =\ 1}) training observation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training_set }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(distance }\OperatorTok{==}\StringTok{ }\KeywordTok{min}\NormalTok{(distance)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(y) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "green"
\end{verbatim}

Since the closest observation in the training data is \texttt{green}, \texttt{K\ =\ 1} classifies our test observation as \texttt{green}.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  What is our prediction with K = 3? Why?
\end{enumerate}

First we find the three closest values. Then we measure the breakdown of \texttt{y} responses in this group of three observations. We find that two observations have value of \texttt{red}, and one has \texttt{green}. Given \texttt{red} has the highest probability of the two \texttt{y} values, we assign the training observation as \texttt{red}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training_set }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{top_n}\NormalTok{(}\DecValTok{3}\NormalTok{, }\OperatorTok{-}\NormalTok{distance) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(y) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{prop =} \KeywordTok{n}\NormalTok{()}\OperatorTok{/}\KeywordTok{max}\NormalTok{(n)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(prop }\OperatorTok{==}\StringTok{ }\KeywordTok{max}\NormalTok{(prop)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "red"
\end{verbatim}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  If Bayes decision boundary is highly non-linear, then do we expect the best value of \(K\) to be large or small? Why?

  \begin{itemize}
  \tightlist
  \item
    We expect the value of \(K\) to decline as the decision boundary grows more non-linear. A smaller value of \(K\) is more suspectible to small changes between observations, which is the type of pattern highly non-linear decision boundary would depict.
  \end{itemize}
\end{enumerate}

The R exercises are pretty basic after this. I am going to skip them for now.

\hypertarget{linear-regression}{%
\chapter{Linear Regression}\label{linear-regression}}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

Linear regression is a simple yet very powerful approach in statistical learning. It is important to have a strong understanding of it before moving on to more complex learning methods.

\hypertarget{packages-used-in-this-chapter}{%
\section{Packages used in this chapter}\label{packages-used-in-this-chapter}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(modelr)}
\end{Highlighting}
\end{Shaded}

\hypertarget{simple-linear-regression}{%
\section{Simple Linear Regression}\label{simple-linear-regression}}

Simple linear regression is predicting a quantitative response \(Y\) based off a single predcitor \(X\).

It can be written as below:

\(Y \approx \beta_0 + \beta_1X\)

\emph{simple linear regression}

\(\beta_0\) and \(\beta_1\) represent the \emph{intercept} and \emph{slope} terms and are together known as the \emph{coefficients}.
\(\beta_0\) and \(\beta_1\) represent the unknown \emph{intercept} and \emph{slope} terms and are together known as the \emph{coefficients}. We will use our training data to estimate these parameters and thus estimate the response \(Y\) based on the value of \(X = x\):

\(\hat y = \hat\beta_0 + \hat\beta_1x\)

\hypertarget{estimating-the-coefficients}{%
\subsection{Estimating the Coefficients}\label{estimating-the-coefficients}}

We need to use data to estimate these coefficients.

\((x_1,y_1), (x_2,y_2),..., (x_n,y_n)\)

These represent the training observations, in this case pairs of \(X\) and \(Y\) measurements. The goal is to use these measurements to estimate \(\beta_0\) and \(\beta_1\) such that the linear model fits our data as close as possible. Measuring \emph{closeness} can be tackled a number of ways, but \href{https://en.wikipedia.org/wiki/Least_squares}{least squares} is the most popular.

If we let \(\hat y_i = \hat\beta_0 + \hat\beta_1x_i\) be the prediction of \(Y\) at observation \(X_i\), then \(e_i = y_i - \hat y_i\) represents the \(i\)th \emph{residual}, the difference between the observed value \(y_i\) and the predicted value \(\hat y_i\). Now we can define the \emph{residual sum of squares (RSS)} as

\(RSS = e_1^2 + e_2^2 + ... + e_n^2\)

\emph{residual sum of squares}

or more explicitly as

\(RSS = (y_1 - \hat\beta_0 - \hat\beta_1x_2)^2 + (y_2 - \hat\beta_0 - \hat\beta_1x_2)^2 + ... + (y_n - \hat\beta_0 - \hat\beta_1x_n)^2\)

Minimizing the RSS (proof can be found \href{https://en.m.wikipedia.org/wiki/Simple_linear_regression\#Derivation_of_simple_regression_estimators}{here}) using \(\beta_0\) and \(\beta_1\) produces:

\(\frac{\displaystyle \sum_{i=1}^{n}(x_i-\bar x)(y_i - \bar x)}{\displaystyle\sum_{i=1}^{n}(x_i - \bar x)^2}\)

\emph{least squares coefficient estimates (simple linear regression)}

\hypertarget{assessing-the-accuracy-of-the-coefficient-estimate}{%
\subsection{Assessing the Accuracy of the Coefficient Estimate}\label{assessing-the-accuracy-of-the-coefficient-estimate}}

Remember that the true function for \(f\) contains a random error term \(\epsilon\). This means the linear relationship can be written as

\(Y = \beta_0 + \beta_1X + \epsilon\)

\emph{population regression line}

\(\beta_0\) is the intercept term (value of \(Y\) when \(X = 0\)). \(\beta_1\) is the slope (how much does \(Y\) change with one-unit change of \(X\)). \(\epsilon\) is the error term that captures everything our model doesn't (unknown variables, measurement error, unknown true relationship).

The population regression line captures the best linear approximation to the true relationship between \(X\) and \(Y\). In real data, we often don't know the true relationship and have to rely on a set of observations. Using the observations to estimate the coefficients via least squares produces the \emph{least squares line}. Let's simulate and visualize this relationship:

\begin{itemize}
\tightlist
\item
  simulate \texttt{n\ =\ 200} observations

  \begin{itemize}
  \tightlist
  \item
    compare the population regression line (\texttt{sim\_y}) to a number of possible least squares lines (generated from 10 different training sets of the data)
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# f(x), or Y = 2 + 2x + error}

\NormalTok{sim_linear <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{b0 =} \DecValTok{2}\NormalTok{,}
  \DataTypeTok{b1 =} \DecValTok{2}\NormalTok{,}
  \DataTypeTok{x =} \DecValTok{1}\OperatorTok{:}\DecValTok{100} \OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DataTypeTok{n =} \DecValTok{200}\NormalTok{, }\DataTypeTok{mean =} \DecValTok{100}\NormalTok{, }\DataTypeTok{sd =} \DecValTok{15}\NormalTok{),}
  \DataTypeTok{err =} \KeywordTok{rnorm}\NormalTok{(}\DecValTok{200}\NormalTok{, }\DataTypeTok{sd =} \DecValTok{50}\NormalTok{),}
  \DataTypeTok{sim_y =}\NormalTok{ b0 }\OperatorTok{+}\StringTok{ }\NormalTok{b1 }\OperatorTok{*}\StringTok{ }\NormalTok{x,}
  \DataTypeTok{true_y =}\NormalTok{ b0 }\OperatorTok{+}\StringTok{ }\NormalTok{b1 }\OperatorTok{*}\StringTok{ }\NormalTok{x }\OperatorTok{+}\StringTok{ }\NormalTok{err}
\NormalTok{)}

\CommentTok{# generate 10 training sets}
\NormalTok{y <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{) \{}
\NormalTok{  x <-}\StringTok{ }\KeywordTok{sample_frac}\NormalTok{(sim_linear, }\FloatTok{0.1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{iter_set =}\NormalTok{ i)}
\NormalTok{  y <-}\StringTok{ }\NormalTok{y }\OperatorTok{%>%}\StringTok{ }\KeywordTok{bind_rows}\NormalTok{(x)}
\NormalTok{\}}

\CommentTok{# apply linear model to each sample}
\NormalTok{by_iter <-}\StringTok{ }\NormalTok{y }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(iter_set) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{nest}\NormalTok{()}
\NormalTok{lm_model <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df) \{}
  \KeywordTok{lm}\NormalTok{(true_y }\OperatorTok{~}\StringTok{ }\NormalTok{x, }\DataTypeTok{data =}\NormalTok{ df)}
\NormalTok{\}}
\NormalTok{by_iter <-}\StringTok{ }\NormalTok{by_iter }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{model =} \KeywordTok{map}\NormalTok{(data, lm_model),}
    \DataTypeTok{preds =} \KeywordTok{map2}\NormalTok{(data, model, add_predictions)}
\NormalTok{  )}

\CommentTok{# extract predictions}
\NormalTok{preds <-}\StringTok{ }\KeywordTok{unnest}\NormalTok{(by_iter, preds)}

\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ sim_linear, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x, }\DataTypeTok{y =}\NormalTok{ true_y)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \DecValTok{1} \OperatorTok{/}\StringTok{ }\DecValTok{3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ preds, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x, }\DataTypeTok{y =}\NormalTok{ pred, }\DataTypeTok{colour =}\NormalTok{ iter_set, }\DataTypeTok{group =}\NormalTok{ iter_set), }\DataTypeTok{linetype =} \StringTok{"F1"}\NormalTok{, }\DataTypeTok{size =} \FloatTok{.75}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ sim_y), }\DataTypeTok{colour =} \StringTok{"red"}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_minimal}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}
    \DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{, }\DataTypeTok{panel.grid.minor =} \KeywordTok{element_blank}\NormalTok{(),}
    \DataTypeTok{panel.grid.major =} \KeywordTok{element_blank}\NormalTok{(), }\DataTypeTok{axis.line =} \KeywordTok{element_line}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"grey92"}\NormalTok{)}
\NormalTok{  ) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}
    \DataTypeTok{title =} \StringTok{"Each least squares line provides a reasonable estimate"}\NormalTok{,}
    \DataTypeTok{y =} \StringTok{"y"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-10-1} \end{center}

The chart above demonstrates the population regression line (red) surrounded by ten different estimates of the least squares line. Notice how every least squares line (shades of blue) is different. This is because each one is generated from a random sample pulled from the simulated data. For a real-world comparison, the simulated data would be the entire population data which is often impossible to obtain. The observations used to generate the least squares line would be the sample data we have access to. In the same way a sample mean can provide a reasonable estimate of the population mean, fitting a least squares line can provide a reasonable estimate of the population regression line.

This comparison of linear regression to estimating population means touches on the topic of bias. An estimate of \(\mu\) using the the sample mean \(\hat\mu\) is unbiased. On average, the sample mean will not systemically over or underestimate \(\mu\). If we were to take a large enough estimates of \(\mu\), each produced by a particular set of observations, then this average would exactly equal \(\mu\). This concept applies to our estimates of \(\beta_0, \beta_1\) as well.

A question that can be asked is how close on average the sample mean \(\hat\mu\) is to \(\mu\). We can compute the \emph{standard error} of \(\hat\mu\) to answer this.

\(Var(\hat\mu) = SE(\hat\mu)^2 = \sigma^2/n\)

\emph{standard error}

This formula measures the average amount that \(\hat\mu\) differs from \(\mu\). As the number of observations \(n\) increases, the standard error decreases.

We can also use this to calculate how close \(\hat\beta_0, \hat\beta_1\) are to \(\beta_0, \beta_1\).

\(SE(\hat\beta_0)^2= \sigma^2 \left[1/n + \frac{\displaystyle \bar x^2}{\displaystyle\sum_{i=1}^{n}(x_i - \bar x)^2} \right]\)

\(SE(\hat\beta_1)^2=\frac{\displaystyle \sigma^2}{\displaystyle\sum_{i=1}^{n}(x_i - \bar x)^2}\)

where \(\sigma^2 = Var(\epsilon)\). For this to work, the assumption has to be made that the error terms \(\epsilon_i\) are uncorrelated and all share a common variance. This is often not the case, but it doesn't mean the formula can't be used for a decent approximation. \(\sigma^2\) is not known, but can be estimated from training observations. This estimate is the \emph{residual standard error} and is given by formula \(RSE = \sqrt{RSS/(n-2}\).

What can we use these standard error formulas for? A useful technique is to calculate \emph{confidence intervals} from the standard error. If we wanted to compute a 95\% confidence interval for \(\beta_0,\beta_1\), it would take the form below.

\(\hat\beta_1 \pm 2 * SE(\hat\beta_1)\)

\(\hat\beta_0 \pm 2 * SE(\hat\beta_0)\)

Standard errors can also be used to perform hypotheses tests.

\(H_0\): There is no relationship between \(X\) and \(Y\), or \(\beta_1 = 0\)

\emph{null hypothesis}

\(H_0\): There exists a relationship between \(X\) and \(Y\), or \(\beta_1 \neq 0\)

\emph{alternative hypothesis}

To test the null hypothesis, we need to test whether \(\hat\beta_1\) is far enough away from zero to conclude that is it non-zero. How far enough from zero is determined by the value of \(\hat\beta_1\) as well as \(SE(\hat\beta_1)\). We compute a \emph{t-statistic}

\(t = (\beta_1 - 0)/SE(\hat\beta_1)\)

\emph{t-statistic}

This measures how many standard deviations \(\hat\beta_1\) is from 0. If there is no relationship between \(X\) and \(Y\), then \(t\) will follow a t-distribution. The t-distribution is similar to the normal distribution, but has slightly heavier tails. Like the normal distribution, we can use this to compute the probability of observing any number equal to or larger than \(|t|\). This probability is the \emph{p-value}. We can interpret a p-value as the probability we would observe the sample data that produced the \(t\)-statistic, given that there is no actual relationship between the predictor \(X\) and the response \(Y\). This means that a small p-value supports the inference that there exists a relationship between the predictor and the response. In this case, based on whichever threshold \(\alpha\) (common value is 0.05) we set, a small enough p-value would lead us to reject the null hypothesis.

\hypertarget{assessing-the-accuracy-of-the-model}{%
\subsection{Assessing the Accuracy of the Model}\label{assessing-the-accuracy-of-the-model}}

Now that we determined the existence of a relationship, how can we measure how well the model fits the data?

Measuring the quality of a linear regression fit is often handled by two quantities: the \emph{residual standard error} and the \emph{R\^{}2} statistic.

\hypertarget{residual-standard-error}{%
\subsubsection{Residual Standard Error}\label{residual-standard-error}}

Since every observation has an associated error term \(\epsilon\), having the knowledge of true \(\beta_0\) and \(\beta_1\) will still not allow one to perfectly predict \(Y\). The residual standard error estimates the standard deviation of the error term.

\(RSE = \sqrt{1/(n-2)*RSS} = \sqrt{1/(n-2)\sum_{i=1}^{n}(y_i - \hat y)^2}\)

\emph{residual standard error}

We can interpret the residual standard error as how much, on average, our predictions deviate from the true value. Whether the value is acceptable in terms of being a successful model depends on the context of the problem. Predicting hardware failure on an airplane would obviously carry much more stringent requirements than predicting the added sales from a change in a company's advertising budget.

\hypertarget{r2-statistic}{%
\subsubsection{R\^{}2 statistic}\label{r2-statistic}}

The RSE provides an absolute number. Given that it depends on the scale of \(Y\), comparing RSE values across different domains and datasets isn't useful. The R\^{}2 statistic solves this problem by measuring in terms of proportion -- it measures the variance explained and so always takes a value between 0 and 1.

\(R^2 = (TSS - RSS)/TSS = 1 - RSS/TSS\)

\emph{R\^{}2 statistic}

where \(TSS = \sum_{i=1}^{n}(y_i-\bar y)^2\) is the \emph{total sum of squares}. TSS can be thought of the amount of total variability in the response variable before any model is fitted to it. RSS is measured after fitting a model, and measures the amount of unexplained variance remaining in the data. Therefore, R\^{}2 can be thought of as the proportion of variance in the data that is explained by fitting a model with \(X\). While R\^{}2 is more intrepetable, determing what constitutes a R\^{}2 is subjective to the problem. Relationships that are known to be linear with little variance would expect an R\^{}2 very close to 1. In reality, a lot of real-world data is not truly linear and could be heavily influenced by unknown, immeasurable predictors. In such cases a linear approximation would be a rough fit, and a smaller R\^{}2 would not be unordinary.

There is a relation between R\^{}2 and the correlation.

\(r = Cor(X,Y) = \sum_{i=1}^{n}((x_i-\bar x)(y_i - \bar y))/(\sqrt{\sum_{i=1}^{n}(x_i - \bar x)^2}\sqrt{\sum_{i=1}^{n}(y_i - \bar y)^2})\)

\emph{correlation}

Both measure the linear relationship between \(X\) and \(Y\), and within the simple linear regression domain, \(r^2 = R^2\). Once we move into multiple linear regression, in which we are using multiple predictors to predict a response, correlation loses effectiveness at measuring a model in whole as it can only measure the relationship between a single pair of variables.

\hypertarget{multiple-linear-regression}{%
\section{Multiple Linear Regression}\label{multiple-linear-regression}}

Simple linear regression works well when the data involves a single predictor variable. In reality, there are often multiple predictor variables. We will need to extend the simple linear regression model and provide each predictor variable \(p\) with a slope coefficient.

\(Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p + \epsilon\)

\emph{multiple linear regression}

\hypertarget{estimating-the-regression-coefficients}{%
\subsection{Estimating the Regression Coefficients}\label{estimating-the-regression-coefficients}}

Again, we need to estimate the regression coefficients.

\(\hat y = \hat\beta_0 + \hat\beta_1X_1 + \hat\beta_2X_2 + ... + \hat\beta_pX_p\)

We will utilize the same approach of minimizing the sum of squared residuals (RSS).

\(RSS = \sum_{i=1}^{n}(y_i - \hat y_i)^2 = \sum_{i=1}^{n}(y_i - \hat\beta_0 - \hat\beta_1x_{i1} - \hat\beta_2x_{i2} - ... - \hat\beta_px_{ip})^2\)

Minimizing these coefficients is more complicated than the simple linear regression setting, and is best represented using linear algebra. See \href{https://en.wikipedia.org/wiki/Residual_sum_of_squares\#Matrix_expression_for_the_OLS_residual_sum_of_squares}{this Wikipedia section} for more information on the formula.

Interpreting a particular coefficient, (say \(\beta_1\)) in a multiple regression model can be thought of as follows: if constant value for all other \(\beta_p\) are maintained, what effect would an increase in \(beta_1\) have on \(Y\)?

A side effect of this is that certain predictors which were deemed significant when contained in a simple linear regression can become insignificant when multiple predictors are involved. For an advertising example, \texttt{newspaper} could be a significant predictor of \texttt{revenue} in the simple linear regression context. However, when combined with \texttt{tv} and \texttt{radio} in a multiple linear regression setting, the effects of increasing \texttt{newspaper} spend while maintaining \texttt{tv} and \texttt{radio} becomes insignificant. This could be due to a correlation of \texttt{newspaper} spend in markets where \texttt{radio} spend is high. Multiple linear regression exposes predictors that act as ``surrogates'' for others due to correlation.

\hypertarget{some-important-questions}{%
\subsection{Some Important Questions}\label{some-important-questions}}

\hypertarget{is-there-a-relationship-between-the-response-and-predictors}{%
\subsubsection{Is There a Relationship Between the Response and Predictors?}\label{is-there-a-relationship-between-the-response-and-predictors}}

To check this, we need to check whethere all \(p\) coefficients are zero, i.e. \(\beta_1 = \beta_2 = ... = \beta_p = 0\). We test the null hypothesis,

\(H_o:\beta_1 = \beta_2 = ... = \beta_p = 0\)

against the alternative

\(H_a:\) at least one \(\beta_j\) is non-zero

The hypothesis test is performed by computing the \(F-statistic\),

\(F = \frac{(TSS-RSS)/p}{RSS/(n-p-1)}\)

\emph{correlation}

If linear model assumptions are correct, one can show that

\(E\{RSS/(n-p-1)\} = \sigma^2\)

and that, provided \(H_o\) is true,

\(E\{(TSS-RSS)/p\} = \sigma^2\)

In simple terms, if \(H_o\) were true and all of the predictors have regression coefficients of 0, we would expect the unexplained variance of the model to be approximately equal to that of the total variance, and both the numerator and the denominator of the F-statistic formula to be equal. When there is no relationship between the response and predictors, the F-statistic will take on a value close to 1. However, as RSS shrinks (the model begins to account for more of the variance), the numerator grows and the denominator shrinks, both causing the F-statistic to increase. We can think of the F-statistic as a ratio between the explained variance and unexplained variance. As the explained variance grows larger than the unexplained portion, the likelihood that we reject the null hypothesis grows.

How large does the F-statistic need to be to reject the null hypothesis? This depends on \(n\) and \(p\). As \(n\) grows, F-statistics closer to 1 may provide sufficient evidence to reject \(H_o\). If \(H_o\) is true and \(\epsilon_i\) have a normal distribution, the F-statistic follows an F-distribution. We can compute the p-value for any value of \(n\) and \(p\) associated with an F-statistic.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# }\AlertTok{TODO}\CommentTok{ remove this section?}
\end{Highlighting}
\end{Shaded}

Sometimes we want to test whether a particular subset of \(q\) of the coefficients are zero.

The null hypothesis could be

\(H_o : \beta_{p-q+1} = \beta_{p-q+2} = \beta_p = 0\)

In this case we fit a second model that uses all the variables except the last \(q\). We will call the residual sum of squares for the second model \(RSS_0\).

Then, the F-statistic is,

\(F = \frac{(RSS_0 - RSS)/q}{RSS(n-p-1)}\)

We are testing a model without the \(q\) predictors and seeing how it compares to the original model containing all the predictors.

Why do we need to look at overall F-statistics if we have individual p-values of the predictors? There are scenarios where individual predictors, by chance, will have \emph{small} p-values, even in the absence of any true association. This could lead us to incorrectly diagnose a relationship.

The overall F-statistic does not suffer this problem because it adjusts for the number of predictors.

The F-statistic approach works when the number of predictors \(p\) is small compared to \(n\). Sometimes, we have situations where \(p > n\). In this situation, ther eare more coefficients \(\beta_j\) to estimate than observations from which to estimate them. Such situations requires different approaches that we haven't discussed yet (see chapter 6)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# }\AlertTok{TODO}\CommentTok{ add chapter 6 link}
\end{Highlighting}
\end{Shaded}

\hypertarget{deciding-on-important-variables}{%
\subsubsection{Deciding on Important Variables}\label{deciding-on-important-variables}}

The first thing we do in a multiple regression is to compute the F-statistic and determine that at least one of the predictors is related to the response.

The task of determining which predictors are associated with the response is referred to as \emph{variable selection}. We could try out a lot of different models with combinations of predictors, \(2^p\), but this is not practical as \(p\) grows.

There are three ways to approach this task:

\begin{itemize}
\item
  \emph{Forward selection}: we begin with the \emph{null model}, which contains an intercept but no predictors. We then fit \(p\) simple linear regressions and add to the null model the variable that results in the lowest RSS. We then repeat the process to determine the lowest RSS of the now two-variable model, continuing until some stopping rule is satisfied.
\item
  \emph{Backward selection}: Start with all the variables in the model, remove the variable with the largest p-value. Then, for the new \((p - 1)\)-variable model, do the same. Continue until stopping rule is reached (for example, some p-value threshold)
\item
  \emph{Mixed selection}: Start with no variables, and proceed with forward selection. If any p-value of added variables pass a threshold once new predictors are added, we remove them. We continue the forward and backward until all variables in model have a sufficiently low p-value.
\end{itemize}

\hypertarget{model-fit}{%
\subsubsection{Model Fit}\label{model-fit}}

Two common methods of model fit are the \(RSE\) and \(R^2\), the fraction of variance explained.

More on \(R^2\):

\begin{itemize}
\tightlist
\item
  Values closer to \texttt{1} indicate a better fit
\item
  Adding more variables can only increase it

  \begin{itemize}
  \tightlist
  \item
    Adding variables that barely increase it can lead to overfitting
  \end{itemize}
\end{itemize}

Plotting the model can also be useful.

\hypertarget{predictions}{%
\subsubsection{Predictions}\label{predictions}}

Three sorts of uncertainty within a given model:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The coefficient estimates \(\hat\beta_0 + \hat\beta_1...,\hat\beta_p\) are estimates for \(\beta_0 + \beta_1...,\beta_p\). This inaccuracy is part of the \emph{reducible error}. We can compute a confidence interval to determine how close \(\hat Y\) is to \(f(X)\).
\item
  \emph{Model bias} can result from the fact that we are fitting a linear approximation to the true surface of \(f(X)\).
\item
  Even if we knew \(f(X)\), we still have random error \(\epsilon\), which is the \emph{irreducible error}. We can use prediction intervals to estimate how far \(Y\) will differ from \(\hat Y\). These will always be larger than confidence intervals, because they incorporate both the reducible + irreducible error.
\end{enumerate}

\hypertarget{other-considerations-in-the-regression-model}{%
\subsection{Other Considerations in the Regression Model}\label{other-considerations-in-the-regression-model}}

So far, all predictors have been \emph{quantitative}. However, it is common to have \emph{qualitative} variables as well.

Take a look at the \texttt{ISLR::Credit} dataset, which has a mix of both types.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_credit <-}\StringTok{ }\NormalTok{ISLR}\OperatorTok{::}\NormalTok{Credit }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{as_tibble}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\NormalTok{janitor}\OperatorTok{::}\KeywordTok{clean_names}\NormalTok{()}
\NormalTok{tidy_credit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 400 x 12
##      id income limit rating cards   age education gender student married
##   <int>  <dbl> <int>  <int> <int> <int>     <int> <fct>  <fct>   <fct>  
## 1     1   14.9  3606    283     2    34        11 " Mal~ No      Yes    
## 2     2  106.   6645    483     3    82        15 Female Yes     Yes    
## 3     3  105.   7075    514     4    71        11 " Mal~ No      No     
## 4     4  149.   9504    681     3    36        11 Female No      No     
## 5     5   55.9  4897    357     2    68        16 " Mal~ No      Yes    
## 6     6   80.2  8047    569     4    77        10 " Mal~ No      No     
## # ... with 394 more rows, and 2 more variables: ethnicity <fct>,
## #   balance <int>
\end{verbatim}

\hypertarget{predictors-with-only-two-levels}{%
\subsubsection{Predictors with only Two Levels}\label{predictors-with-only-two-levels}}

Suppose we wish to investigate difference in credit card balance between males and females, ignoring all other variables. If a \emph{qualitative} variable (also known as a \emph{factor}) only has two possible values, then incorporating it into a model is easy. We can create a binomial dummy variable that takes on two values. For \texttt{gender}, this could be a variable that is \texttt{0} if observation has value \texttt{male}, and \texttt{1} if observation has value \texttt{female}. This variable can then be used in the regression equation.

Take note that \texttt{lm()} automatically creates dummy variables when given qualitative predictors.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# }\AlertTok{TODO}\CommentTok{ insert regression equation}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{credit_model <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(balance }\OperatorTok{~}\StringTok{ }\NormalTok{gender, }\DataTypeTok{data =}\NormalTok{ tidy_credit)}
\NormalTok{tidy_credit_model <-}\StringTok{ }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{(credit_model)}
\NormalTok{tidy_credit_model}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   term         estimate std.error statistic  p.value
##   <chr>           <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)     510.       33.1    15.4   2.91e-42
## 2 genderFemale     19.7      46.1     0.429 6.69e- 1
\end{verbatim}

How to interpret this: males are estimated to carry a balance of \texttt{\$510}. Meanwhile, females are expected to carry an additional \(19.70\) in debt. Notice the p-value is very high, indicating there is no significant difference between genders.

\hypertarget{qualitative-predictors-with-more-than-two-levels}{%
\subsection{Qualitative Predictors with More than Two Levels}\label{qualitative-predictors-with-more-than-two-levels}}

A single dummy variable can not represent all the possible values. We can create additional dummy variables for this.

Let's make a dummy variable from \texttt{ethnicity} column, which takes three distinct values. This will yield two dummy variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_credit }\OperatorTok{%>%}\StringTok{ }\KeywordTok{distinct}\NormalTok{(ethnicity)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 1
##   ethnicity       
##   <fct>           
## 1 Caucasian       
## 2 Asian           
## 3 African American
\end{verbatim}

\texttt{fastDummies} package will be used to generate these. In this case, \texttt{African\ American} serves as the baseline, and dummy variables are created for \texttt{Caucasian} and \texttt{Asian}. \textbf{There will always be one fewer dummy variable than the number of levels.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_credit_dummy <-}\StringTok{ }\NormalTok{tidy_credit }\OperatorTok{%>%}
\StringTok{  }\NormalTok{fastDummies}\OperatorTok{::}\KeywordTok{dummy_cols}\NormalTok{(}\DataTypeTok{select_columns =} \StringTok{"ethnicity"}\NormalTok{, }\DataTypeTok{remove_first_dummy =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{janitor}\OperatorTok{::}\KeywordTok{clean_names}\NormalTok{()}

\NormalTok{tidy_credit_dummy }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{starts_with}\NormalTok{(}\StringTok{"ethnicity"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 400 x 3
##   ethnicity ethnicity_asian ethnicity_caucasian
##   <fct>               <int>               <int>
## 1 Caucasian               0                   1
## 2 Asian                   1                   0
## 3 Asian                   1                   0
## 4 Asian                   1                   0
## 5 Caucasian               0                   1
## 6 Caucasian               0                   1
## # ... with 394 more rows
\end{verbatim}

We can again run the model with newly created dummy variables. Keep in mind, prior creation is not necessary, as \texttt{lm} will generate them automatically.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ethnicity_model <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(balance }\OperatorTok{~}\StringTok{ }\NormalTok{ethnicity_asian }\OperatorTok{+}\StringTok{ }\NormalTok{ethnicity_caucasian, }\DataTypeTok{data =}\NormalTok{ tidy_credit_dummy)}
\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{(ethnicity_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   term                estimate std.error statistic  p.value
##   <chr>                  <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)            531.       46.3    11.5   1.77e-26
## 2 ethnicity_asian        -18.7      65.0    -0.287 7.74e- 1
## 3 ethnicity_caucasian    -12.5      56.7    -0.221 8.26e- 1
\end{verbatim}

\hypertarget{extensions-of-the-linear-model}{%
\subsection{Extensions of the Linear Model}\label{extensions-of-the-linear-model}}

The linear regression model makes highly restrictive assumptions. Two of the most important are that the relationship between predictors and response are \emph{additive} and \emph{linear}.

Additive means that the effect of changes in a predictor \(X_j\) on the response \(Y\) is independet of the values of the other predictors. Linear means that the the change in response \(Y\) to a one-unit change in \(X_j\) is constant, regardless of the value of \(X_j\).

Here are some common approaches of extending the linear model.

\hypertarget{removing-the-additive-assumption}{%
\subsubsection{Removing the Additive Assumption}\label{removing-the-additive-assumption}}

The additive property assumes that predictors slope terms are independent of the values of other predictors. However, this is not always the case. Imagine an advertising scenario where the effectiveness of TV spend is affected by the radio spend. This is known as an \emph{interaction} effect. Imagine we have a model with two predictors, but they are not strictly additive. We could extend this model by adding an \emph{interaction term} to it.

\(Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_1X_2 + \epsilon\)

Now, the effect of \(X_1\) on \(Y\) is no longer constant; adjusting \(X_2\) will change the impact of \(X_1\) on \(Y\).

An easy scenario is the productivity of a factory. Adding lines and workers both would increase productivity. However, the effect is not purely additive. Adding lines without having workers to operate them would not increase productivity. There is an interaction between workers and lines that needs to be accounted for.

The \emph{hierarchical principle} states that \emph{if we include an interaction in a model, we should also include the main effects, even if the p-values associated with their coefficients are not significant}.

It's also possible for qualitative and quantitative variables to interact with each other. We will again use the \texttt{Credit} data set. Suppose we wish to predict \texttt{balance} using the \texttt{income} (quantitative) and \texttt{student} (qualitative) variables.

First, let's take a look at what it looks like to fit this model without an interaction term. Both \texttt{income} and \texttt{student} are significant.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_credit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(balance }\OperatorTok{~}\StringTok{ }\NormalTok{income }\OperatorTok{+}\StringTok{ }\NormalTok{student, }\DataTypeTok{data =}\NormalTok{ tidy_credit)}
\NormalTok{lm_credit }\OperatorTok{%>%}\StringTok{ }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   term        estimate std.error statistic  p.value
##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)   211.      32.5        6.51 2.34e-10
## 2 income          5.98     0.557     10.8  7.82e-24
## 3 studentYes    383.      65.3        5.86 9.78e- 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_credit }\OperatorTok{%>%}
\StringTok{  }\NormalTok{modelr}\OperatorTok{::}\KeywordTok{add_predictions}\NormalTok{(lm_credit) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ income, }\DataTypeTok{y =}\NormalTok{ pred, }\DataTypeTok{colour =}\NormalTok{ student)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{size =} \FloatTok{1.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ balance, }\DataTypeTok{colour =}\NormalTok{ student), }\DataTypeTok{fill =} \StringTok{"grey"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{21}\NormalTok{, }\DataTypeTok{alpha =} \DecValTok{1} \OperatorTok{/}\StringTok{ }\DecValTok{2}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-18-1} \end{center}

It's a pretty good fit, and because there is no interaction terms, the lines are parallel. Notice how many more observations there are to fit on for the non-students.

Now, let's add an interaction term.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_credit_int <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(balance }\OperatorTok{~}\StringTok{ }\NormalTok{income }\OperatorTok{+}\StringTok{ }\NormalTok{student }\OperatorTok{+}\StringTok{ }\NormalTok{income }\OperatorTok{*}\StringTok{ }\NormalTok{student, }\DataTypeTok{data =}\NormalTok{ tidy_credit)}
\NormalTok{lm_credit_int }\OperatorTok{%>%}\StringTok{ }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 5
##   term              estimate std.error statistic  p.value
##   <chr>                <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)         201.      33.7        5.95 5.79e- 9
## 2 income                6.22     0.592     10.5  6.34e-23
## 3 studentYes          477.     104.         4.57 6.59e- 6
## 4 income:studentYes    -2.00     1.73      -1.15 2.49e- 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_credit }\OperatorTok{%>%}
\StringTok{  }\NormalTok{modelr}\OperatorTok{::}\KeywordTok{add_predictions}\NormalTok{(lm_credit_int) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ income, }\DataTypeTok{y =}\NormalTok{ pred, }\DataTypeTok{colour =}\NormalTok{ student)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{size =} \FloatTok{1.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ balance, }\DataTypeTok{colour =}\NormalTok{ student), }\DataTypeTok{fill =} \StringTok{"grey"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{21}\NormalTok{, }\DataTypeTok{alpha =} \DecValTok{1} \OperatorTok{/}\StringTok{ }\DecValTok{2}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-20-1} \end{center}

The model now takes into account how \texttt{income} and \texttt{student} interact with each other. Interpreting the chart suggests that increases in \texttt{income} among students has a smaller effect on balance than it does to non-students.

Does it fit better?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{models <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{without_interaction =}\NormalTok{ lm_credit, }\DataTypeTok{with_interaction =}\NormalTok{ lm_credit_int)}
\NormalTok{purrr}\OperatorTok{::}\KeywordTok{map_df}\NormalTok{(models, broom}\OperatorTok{::}\NormalTok{glance, }\DataTypeTok{.id =} \StringTok{"model"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(model, r.squared, statistic, p.value, df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   model               r.squared statistic  p.value    df
##   <chr>                   <dbl>     <dbl>    <dbl> <int>
## 1 without_interaction     0.277      76.2 9.64e-29     3
## 2 with_interaction        0.280      51.3 4.94e-28     4
\end{verbatim}

Not by much. The model with the interaction term has a slightly higher \(R^2\), but the added complexity of the model, combined with the small number of observations of students in the dataset, suggests overfitting.

\hypertarget{non-linear-relationships}{%
\subsubsection{Non-linear Relationships}\label{non-linear-relationships}}

The linear model assumes a linear relationship between the response and predictors. We can extend the linear model to accomodate non-linear relationships using \emph{polynomial regression}.

A way to incorporate non-linear associations into a linear model is to include transformed versions of the predictor in the model. For example, within the \texttt{Auto} dataset, predicting \texttt{mpg} with a second-order polynomial of \texttt{horsepower} would look like this:

\(mpg = \beta_0 + \beta_1horsepower + \beta_2horsepower^2 + \epsilon\)

Let's look at the \texttt{Auto} dataset with models of different polynomial degrees overlaid. Clearly, the data is not linear, exhibiting a \emph{quadratic} shape.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_auto <-}\StringTok{ }\NormalTok{ISLR}\OperatorTok{::}\NormalTok{Auto }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as_tibble}\NormalTok{()}

\NormalTok{lm_auto <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(mpg }\OperatorTok{~}\StringTok{ }\NormalTok{horsepower, }\DataTypeTok{data =}\NormalTok{ tidy_auto)}
\NormalTok{lm_auto2 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(mpg }\OperatorTok{~}\StringTok{ }\KeywordTok{poly}\NormalTok{(horsepower, }\DecValTok{2}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ tidy_auto)}
\NormalTok{lm_auto5 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(mpg }\OperatorTok{~}\StringTok{ }\KeywordTok{poly}\NormalTok{(horsepower, }\DecValTok{5}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ tidy_auto)}

\NormalTok{tidy_auto }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather_predictions}\NormalTok{(lm_auto, lm_auto2, lm_auto5) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ horsepower, }\DataTypeTok{y =}\NormalTok{ mpg)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \DecValTok{1} \OperatorTok{/}\StringTok{ }\DecValTok{3}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{21}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ pred, }\DataTypeTok{colour =}\NormalTok{ model), }\DataTypeTok{size =} \FloatTok{1.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-22-1} \end{center}

The second-order polynomial does a good job of fitting the data, while the fifth-order seems to be unnecessary. The model performance reflects that:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{models <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}
  \DataTypeTok{linear =}\NormalTok{ lm_auto,}
  \DataTypeTok{second_order =}\NormalTok{ lm_auto2,}
  \DataTypeTok{fifth_order =}\NormalTok{ lm_auto5}
\NormalTok{)}
\NormalTok{purrr}\OperatorTok{::}\KeywordTok{map_df}\NormalTok{(models, broom}\OperatorTok{::}\NormalTok{glance, }\DataTypeTok{.id =} \StringTok{"model"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(model, r.squared, statistic, p.value, df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   model        r.squared statistic  p.value    df
##   <chr>            <dbl>     <dbl>    <dbl> <int>
## 1 linear           0.606      600. 7.03e-81     2
## 2 second_order     0.688      428. 5.40e-99     3
## 3 fifth_order      0.697      177. 1.16e-97     6
\end{verbatim}

The second-order model has significantly higher R\^{}2, and only one more degree of freedom.

This approach of extending linear models to accomodate non-linear relationships is known as polynomial regression.

\hypertarget{potential-problems}{%
\subsection{Potential Problems}\label{potential-problems}}

Many problems can occur when fitting a linear model to a data set.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Non-linearity of the response-predictor relationship.
\item
  Correlation of error terms.
\item
  Non-constant variance of error terms
\item
  Outliers
\item
  High-leverage points
\item
  Collinearity
\end{enumerate}

\hypertarget{non-linearity-of-the-data}{%
\subsubsection{1. Non-linearity of the data}\label{non-linearity-of-the-data}}

The linear model assumes a straight-line relationship between the predictors and the response. If this is not the case, the inference and prediction accuracy of the fit are suspect.

We can use a \emph{residual plot} to visualize when a linear model is placed on to a non-linear relationship. For a simple linear regression model, we plot the residuals \(e_i = y_i - \hat{y}_i\) compared to the predictor. For multiple regression, we plot the residuals versus the predicted values \(\hat{y}_i\). If the relationship is linear, the residuals should exhibit a random pattern.

Let's take the \texttt{Auto} dataset and plot the residuals compared to \texttt{horsepower} for each model we fit. Notice in the model containing no quadratic term is U-shaped, indicating a non-linear relationship. The model that contains \texttt{horsepower\^{}2} exhibits little pattern in the residuals, indicating a better fit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_auto }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather_predictions}\NormalTok{(lm_auto, lm_auto2, lm_auto5) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ horsepower, }\DataTypeTok{y =}\NormalTok{ mpg}\OperatorTok{-}\NormalTok{pred, }\DataTypeTok{colour=}\NormalTok{model)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \DecValTok{1} \OperatorTok{/}\StringTok{ }\DecValTok{3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.5}\NormalTok{, }\DataTypeTok{colour=}\StringTok{"grey"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{model, }\DataTypeTok{nrow=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-24-1} \end{center}

If the residual plot indicates that there non-linear associations in the data, a simple approach is to use non-linear transofmrations of the predictors.

\hypertarget{correlation-of-error-terms}{%
\subsubsection{2. Correlation of Error Terms}\label{correlation-of-error-terms}}

The linear regression model assumes that the error terms \(\epsilon_1,\epsilon_2,...,\epsilon_n\) are uncorrelated.

This means that for a given error term \(e_i\), no information is provided about the value \(e_{i+1}\). The standard errors that are computed for the estimated regression coefficients are based on this assumption.

If there is a correlation among the error terms, than the estimated standard errors will tend to underestimate the true standard errors, producing confidence and prediction intervals narrower than they should be. Given the incorrect assumption, a 95\% confidence interval may have a much lower probability than 0.95 of containing the true value of the parameter. P-values would also be lower than they should be, giving us an unwarranted sense of confidence in our model.

These correlations occur frequently in \emph{time series} data, which consists of observations obtained at discrete points in time. In many cases, observations that are obtained at adjacent time periods points will have positively correlated errors.

We can again plot the residuals as a function of time to see if this is the case. If no correlation, there should be no pattern in the residuals. If error terms exhibit correlation, we may see that adjacent residuals exhibit similar values, known as \emph{tracking}.

This can also happen outside of time series data. The assumption of uncorrelated errors is extremely important for linear regression as well as other statistical methods.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# }\AlertTok{TODO}\CommentTok{ add a residual plot for time series with correlated error terms, similar to pg. 95}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_sunspot <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{y=}\KeywordTok{as.matrix}\NormalTok{(sunspot.year), }\DataTypeTok{ds=}\KeywordTok{time}\NormalTok{(sunspot.year)) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as_tibble}\NormalTok{()}
\NormalTok{tidy_sunspot}
\NormalTok{sunspot_lm <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tidy_sunspot, y }\OperatorTok{~}\StringTok{ }\NormalTok{ds)}
\NormalTok{tidy_sunspot }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{add_predictions}\NormalTok{(sunspot_lm) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{ds, }\DataTypeTok{y=}\NormalTok{pred}\OperatorTok{-}\NormalTok{y)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"lm"}\NormalTok{, }\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{non-constant-variance-of-error-terms}{%
\subsubsection{3. Non-constant Variance of Error Terms}\label{non-constant-variance-of-error-terms}}

Another assumption of linear regression is that the error terms have a constant variance, \(Var(\epsilon_i) = \sigma^2\). Standard errors, confidence intervals, and hypothesis tests rely upon this assumption.

It is common for error terms to exhiti non-constant variance. Non-constant variance in the errors, also known as \emph{heteroscedasticity}, can be identified from a \emph{funnel shape} in the residual plot.

Let's take a look at the \texttt{MASS::cats} dataset, which contains observations of various cats sex, body weight, and heart weight. We fit a linear model to it, and then plot the residuals.

I've added a linear fit to the residual plot itself. Observe how the error terms begin to funnel out as \texttt{bwt} increases, indicating non-constant variance of the error terms.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_cats <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\NormalTok{cats }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as_tibble}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }\NormalTok{janitor}\OperatorTok{::}\KeywordTok{clean_names}\NormalTok{()}
\NormalTok{lm_cats <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tidy_cats, hwt }\OperatorTok{~}\StringTok{ }\NormalTok{bwt)}

\NormalTok{tidy_cats }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{add_predictions}\NormalTok{(lm_cats) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ bwt, }\DataTypeTok{y =}\NormalTok{ hwt }\OperatorTok{-}\StringTok{ }\NormalTok{pred)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"lm"}\NormalTok{, }\DataTypeTok{level =} \FloatTok{0.99}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-26-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# }\AlertTok{TODO}\CommentTok{ add OLS method to this}
\CommentTok{# get weights of each response}

\CommentTok{# fit a linear model on the residuals}
\NormalTok{tidy_cats_res <-}\StringTok{ }\NormalTok{tidy_cats }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{add_predictions}\NormalTok{(lm_cats) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{res =}\NormalTok{ hwt }\OperatorTok{-}\StringTok{ }\NormalTok{pred) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(bwt, hwt, res)}
\NormalTok{lm_cats_res <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tidy_cats_res, res }\OperatorTok{~}\StringTok{ }\NormalTok{hwt)}

\NormalTok{cat_weights <-}\StringTok{ }\NormalTok{tidy_cats_res }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{add_predictions}\NormalTok{(lm_cats_res) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{res_var =}\NormalTok{ (res}\OperatorTok{-}\NormalTok{pred)}\OperatorTok{^}\DecValTok{2}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{weight =} \DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{res_var) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{(weight)}

\NormalTok{lm_cats_weights <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tidy_cats, hwt }\OperatorTok{~}\StringTok{ }\NormalTok{bwt, }\DataTypeTok{weights =}\NormalTok{ cat_weights)}

\NormalTok{tidy_cats }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather_predictions}\NormalTok{(lm_cats, lm_cats_weights) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ bwt, }\DataTypeTok{y =}\NormalTok{ hwt }\OperatorTok{-}\StringTok{ }\NormalTok{pred, }\DataTypeTok{colour =}\NormalTok{ model)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ hwt}\OperatorTok{-}\NormalTok{pred, }\DataTypeTok{colour =}\NormalTok{ model)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"lm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

When this occurs, there a few ways to remedy it. You could transform the response \(Y\) using a function such as \(logY\) or \(\sqrt{Y}\). If we have a good idea of the variance of each response, we could fit our model using \emph{weighted least squares}, which weights proportional to the inverse of the expected variance of an observation.

\hypertarget{outliers}{%
\subsubsection{4. Outliers}\label{outliers}}

An \emph{outlier} is a point for which \(y_i\) is far from the value predicted by the model. These can arise for a variety of reasons, such as incorrect recording of an observation during data collection.

For the \texttt{msleep} dataset below, which contains data on mammal sleep durations, I've highlighted two observations that most would consider outliers. This is for the \texttt{African\ elephant} and \texttt{Asian\ elephant} mammals, who's bodyweights are far and away from the rest of mammals. There are others that could be considered outliers as well. Identifying outliers is an often arbitrary process.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{msleep }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ awake, }\DataTypeTok{y =}\NormalTok{ bodywt, }\DataTypeTok{colour =}\NormalTok{ name)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\NormalTok{gghighlight}\OperatorTok{::}\KeywordTok{gghighlight}\NormalTok{(bodywt}\OperatorTok{>}\DecValTok{2000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-28-1} \end{center}

Let's fit a linear model to predict body weight from how long the animal is awake.

Notice how the data that maintains the elephant observations significantly affects the slope, drawing the regression line away from the majority of observations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_sleep <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ msleep, bodywt }\OperatorTok{~}\StringTok{ }\NormalTok{awake)}
\NormalTok{lm_sleep_filtered <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ msleep }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\NormalTok{name }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'African elephant'}\NormalTok{, }\StringTok{'Asian elephant'}\NormalTok{)), bodywt }\OperatorTok{~}\StringTok{ }\NormalTok{awake)}
\NormalTok{msleep }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather_predictions}\NormalTok{(lm_sleep, lm_sleep_filtered) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ awake, }\DataTypeTok{y =}\NormalTok{ bodywt)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{pch=}\DecValTok{21}\NormalTok{, }\DataTypeTok{alpha =} \DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ pred, }\DataTypeTok{colour =}\NormalTok{ model), }\DataTypeTok{size =} \FloatTok{1.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_colour_viridis_d}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-29-1} \end{center}

The model excluding the elephant observations has a significantly higher \(R^2\), which indicates a better fit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{models <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{with_outliers =}\NormalTok{ lm_sleep,}
               \DataTypeTok{without_outliers =}\NormalTok{ lm_sleep_filtered)}
\NormalTok{purrr}\OperatorTok{::}\KeywordTok{map_df}\NormalTok{(models, broom}\OperatorTok{::}\NormalTok{glance, }\DataTypeTok{.id =} \StringTok{"model"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(model, r.squared, statistic, p.value, df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   model            r.squared statistic    p.value    df
##   <chr>                <dbl>     <dbl>      <dbl> <int>
## 1 with_outliers       0.0973      8.73 0.00409        2
## 2 without_outliers    0.222      22.5  0.00000900     2
\end{verbatim}

Another way of handling an outlier is transforming the response variable. Upon inspection of the scatterplot, it becomes clear that the relationship between \texttt{bodywt} and \texttt{awake} is not linear. If we take the same dataset and apply a \texttt{log} function to response variable \texttt{bodywt}, we see that the outliers no longer exists.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{msleep }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ awake, }\DataTypeTok{y =} \KeywordTok{log}\NormalTok{(bodywt))) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-31-1} \end{center}

The model that uses \texttt{log(bodywt)} as the response also has better performance than both models above.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_sleep_log <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ msleep, }\KeywordTok{log}\NormalTok{(bodywt) }\OperatorTok{~}\StringTok{ }\NormalTok{awake)}
\NormalTok{lm_sleep_log }\OperatorTok{%>%}\StringTok{ }\NormalTok{broom}\OperatorTok{::}\KeywordTok{glance}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(r.squared, statistic, p.value, df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 4
##   r.squared statistic      p.value    df
##       <dbl>     <dbl>        <dbl> <int>
## 1     0.324      38.7 0.0000000202     2
\end{verbatim}

\hypertarget{high-leverage-points}{%
\subsubsection{5. High Leverage Points}\label{high-leverage-points}}

Observations with \emph{high leverage} have an unusual value for \(x_i\). In a simple regression model, these are practically the same as outliers (I could have flipped predictors with response in my mammal sleep model above). High leverage points are observations that significantly move the regression line. However, in multiple regression, it is possible to have an observation that is well within the range of each individual predictor's values, but unusual terms of the full set of predictors.

Let's look at \texttt{temp} and \texttt{ozone} data from \texttt{airquality} dataset. Plenty of observations have ozone \textgreater{} \texttt{100} and temp \textless{} \texttt{80}, but the combination is rare. If we fit models with and without this leverage point, we can see how the regression line moves.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_airquality <-}\StringTok{ }\NormalTok{airquality }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{as_tibble}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\NormalTok{janitor}\OperatorTok{::}\KeywordTok{clean_names}\NormalTok{()}

\NormalTok{tidy_airquality }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ozone, }\DataTypeTok{y =}\NormalTok{ temp)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\NormalTok{gghighlight}\OperatorTok{::}\KeywordTok{gghighlight}\NormalTok{(ozone }\OperatorTok{>}\StringTok{ }\DecValTok{100} \OperatorTok{&}\StringTok{ }\NormalTok{temp }\OperatorTok{<}\StringTok{ }\DecValTok{80}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-33-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_temp <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tidy_airquality, temp }\OperatorTok{~}\StringTok{ }\NormalTok{ozone)}
\NormalTok{lm_temp_filtered <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tidy_airquality }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\NormalTok{(ozone }\OperatorTok{>}\StringTok{ }\DecValTok{100} \OperatorTok{&}\StringTok{ }\NormalTok{temp }\OperatorTok{<}\StringTok{ }\DecValTok{80}\NormalTok{)), temp }\OperatorTok{~}\StringTok{ }\NormalTok{ozone)}
\end{Highlighting}
\end{Shaded}

Notice the slight change in the fit. This observation isn't that extreme, but still produces a visible difference in fit. More extreme observations would move this line even further, potentially causing an improper fit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_airquality }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather_predictions}\NormalTok{(lm_temp, lm_temp_filtered) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ozone, }\DataTypeTok{y =}\NormalTok{ pred, }\DataTypeTok{colour =}\NormalTok{ model)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ temp), }\DataTypeTok{alpha =} \DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{, }\DataTypeTok{colour =} \StringTok{"grey"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-35-1} \end{center}

The model without the strange observation performs slightly better. In reality, I would probably include it as going from an \(R^2\) of \texttt{0.488} to \texttt{0.506} isn't worth the manual effort.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{models <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{with_leverage =}\NormalTok{ lm_temp,}
               \DataTypeTok{without_leverage =}\NormalTok{ lm_temp_filtered)}
\NormalTok{purrr}\OperatorTok{::}\KeywordTok{map_df}\NormalTok{(models, broom}\OperatorTok{::}\NormalTok{glance, }\DataTypeTok{.id =} \StringTok{"model"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(model, r.squared, statistic, p.value, df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   model            r.squared statistic  p.value    df
##   <chr>                <dbl>     <dbl>    <dbl> <int>
## 1 with_leverage        0.488      109. 2.93e-18     2
## 2 without_leverage     0.506      116. 5.05e-19     2
\end{verbatim}

We can also quantify an observation's leverage by computing the \(leverage statistic\). A large value of this statistic indicates an observation with high leverage. For a simple linear regression,

\(h_i = \frac{1}{n} + \frac{x_i - \bar{x}^2}{\sum_{i'=1}^{n}}\)

\emph{leverage statistic}

As \(x_i\) increases from \(\bar{x}\), \(h_i\) increases. Combined with a high residual (outlier), a high-leverage observation could be dangerous.

\hypertarget{colinearity}{%
\subsubsection{6. Colinearity}\label{colinearity}}

\texttt{Collinearity} is when two or more predictor variables are closely related to one another.

If we look at our \texttt{tidy\_credit} tibble, we see that \texttt{rating} and \texttt{limit} are very highly correlated with one another.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_credit }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ rating, }\DataTypeTok{y =}\NormalTok{ limit)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-37-1} \end{center}

The effects of collinearity can make it difficult to separate out the individual effects of collinear variables on the response. Since \texttt{limit} and \texttt{rating} move together, it can be hard to determine how each one separately is associated with the response, \texttt{balance}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# }\AlertTok{TODO}\CommentTok{ add contour plot}
\CommentTok{# clean up what this link did: https://yetanotheriteration.netlify.com/2018/01/high-collinearity-effect-in-regressions/}
\end{Highlighting}
\end{Shaded}

Two multiple regression models show the effects of regressing \texttt{balance} on \texttt{age\ +\ limit} versus \texttt{rating\ +\ limit}. Notice the large p-value for \texttt{limit}, combined with the \textgreater{}10x increase in standard error for its coefficient compared to the original model. It's effects have been masked by the collinearity it shares with \texttt{rating}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_age_limit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tidy_credit, balance }\OperatorTok{~}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{limit)}
\NormalTok{lm_rating_limit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tidy_credit, balance }\OperatorTok{~}\StringTok{ }\NormalTok{rating }\OperatorTok{+}\StringTok{ }\NormalTok{limit)}
\NormalTok{models <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\StringTok{`}\DataTypeTok{Balance ~ Age + Limit}\StringTok{`}\NormalTok{ =}\StringTok{ }\NormalTok{lm_age_limit,}
               \StringTok{`}\DataTypeTok{Balance ~ Rating + Limit}\StringTok{`}\NormalTok{ =}\StringTok{ }\NormalTok{lm_rating_limit)}
\NormalTok{purrr}\OperatorTok{::}\KeywordTok{map_df}\NormalTok{(models, broom}\OperatorTok{::}\NormalTok{tidy, }\DataTypeTok{.id =} \StringTok{"model"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 6
##   model                  term        estimate std.error statistic   p.value
##   <chr>                  <chr>          <dbl>     <dbl>     <dbl>     <dbl>
## 1 Balance ~ Age + Limit  (Intercept) -1.73e+2  43.8        -3.96  9.01e-  5
## 2 Balance ~ Age + Limit  age         -2.29e+0   0.672      -3.41  7.23e-  4
## 3 Balance ~ Age + Limit  limit        1.73e-1   0.00503    34.5   1.63e-121
## 4 Balance ~ Rating + Li~ (Intercept) -3.78e+2  45.3        -8.34  1.21e- 15
## 5 Balance ~ Rating + Li~ rating       2.20e+0   0.952       2.31  2.13e-  2
## 6 Balance ~ Rating + Li~ limit        2.45e-2   0.0638      0.384 7.01e-  1
\end{verbatim}

The growth in the standard error caused by collinearity caises the t-statistic (\(B_j\) divided by it's standard error) to decline. As a result, we may fail to reject \(H_0: \beta_j = 0\). This means that the \emph{power} of the hypothesis test -- the probability of correctly detecting a non-zero coefficient -- is reduced by collinearity. Thus, it is desirable to identify and address collinearity problems while fitting the model.

A simple way is to look at the correlation matrix of the predoctors.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(corrr)}
\NormalTok{tidy_credit }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select_if}\NormalTok{(is.numeric) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{id) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{corrr}\OperatorTok{::}\KeywordTok{correlate}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\NormalTok{corrr}\OperatorTok{:::}\KeywordTok{stretch}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{tidy_islr_files/figure-latex/unnamed-chunk-40-1} \end{center}


\end{document}
